通用代码优化见 https://github.com/pingz1988/Linux/blob/master/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Readme.md  
以下是关于DPDK应用程序优化  

## DPDK应用程序设计准则 
* 数据本地化  
* 无锁化

## 两种模式  
* pipline  
* run-to-completion  
在不同的应用需求下，一种模式的性能表现会比另一种强  

## 优化方法一
1. 找出程序的热点代码（利用perf/VTune等工具）
2. 参考DPDK相关代码（包括配置、选项）进行优化，也可考虑改造DPDK提供的单元测试代码来对自己的应用程序测试。  
    2.1 用系统API去时间评估性能，系统开销太大。rte_rdtsc() 是个很好的实现，一条汇编指令，在怀疑性能的地方使用宏PERF_START、PERF_COUNT、PERF_DUMP
3. 重复上述步骤直到性能达到预期  

## 优化方法二 
修改 DPDK l2fwd 示例程序，修改后，将其作为参考基准，优化自己的程序：
1.增加配置功能，可以根据 NUMA 配置 CPU  
2.去掉修改 MAC 的功能  
3.减少mbuf mempool的个数，这样做是为了提升cache利用率 
4.测试仪配置时，将其改为不需要学习arp就能二层测试  
按照修改示例后的性能为基准，来优化自己的程序，使整体性能达到最优值。

# 非代码方面  
* BIOS设置  
* 操作系统feature开关  
* 分配大页
* CPU配置，收包/包处理分配的CPU是否跨NUMA
  
# 代码方面
## 内存
* 内存对齐   
  结构体按cache line大小64字节对齐，结构体中的成员变量按占用内存从大到小排列
* API  
  dpdk内部实现了内存相关的操作函数，考虑了内存对齐、NUMA、内存通道分布等等因素，它们更高效，尤其对于大内存分配的分配及操作，比如rte_malloc/rte_free/rte_memcpy/rte_strcpy，尽量使用这些函数，避免使用libc内存操作函数。类似地，还有rte_ring（lcore间的通信）/rte_mempool（大内存分配）/rte_hash 等
* 多lcore读写访问内存  
  不同lcore对同一块内存的进行读写访问会造成大量cache-miss，每个核单独使用的变量用 RTE_PER_LCORE 宏修饰，只是读访问的话不需要这个处理
* NUMA  
  lcore的使用需注意它所在的NUMA节点，跨NUMA访问，会造成cache-miss，rte_mempool/rte_ring/rte_malloc等都考虑了跨NUMA问题

## Cache
* 分支预测  
  使用likely/unlikey，多条件分支，按出现概率从大到小排列
* 数据预取  
  合理使用数据预取，**需谨慎使用，也不能过度使用，需反复测试，否则性能反而会下降**。  
  1、硬件预取，由硬件实现，略过  
  2、软件预取：处理批量数据时用rte_prefetch0()预取一个cache line数据到cache中，处理单个数据时用rte_prefetch_non_temporal()预取一个cache line数据到cache中。不要在内层循环的末尾使用（非末尾处可以使用）数据预取指令，在外层循环中预取内层循环数据。
  ```c
  for (ii = 0; ii < 100; ii++) {
    for (jj = 0; jj < 24; jj+=8) { /* N-1 iterations */
        prefetch a[ii][jj+8]
        computation a[ii][jj]
    }
    prefetch a[ii+1][0]
    computation a[ii][jj]/* Last iteration */
  }
  ```
  
## 多线程/超线程  
  可以的话，使用非阻塞API，如pthread_mutex_try_lock.  
  使用ring进行线程/进程间通信。   
  在对称多处理器/具有超线程技术的CPU上，线程可以通过并行计算显著提高性能。  
  使用模式：1、数据分解（使用OpenMP指令，让编译器做并行化处理）；2、功能分解（显式调用线程库API）；3、其它（生产者-消费者）。
  * 线程同步  
    - 自旋循环（spin-wait，不断检测，忙等锁，适用于在很快(1/100s)就能获取资源的情况下）中用PAUSE指令
    - 自旋锁替代
    - 会长时间空闲的线程中，使用线程阻塞API
    - 避免false sharing
    - 用于线程间同步的变量单独存放在cache line中
  * Bus总线的利用
  * 内存优化
  * 前端优化
  * 执行资源优化

## 无锁化  
   使用锁会带来性能损耗，可考虑使用单核变量（per-lcore）、RCU（Read-Copy-update，DPDK提供了RCU库，但文档警告这个库会在不事前通知的情况下被更改）算法替代读写锁（rwlock），从而实现无锁化  
     
## 数据结构
* mempool  
默认是基于ring方式，**基于stack方式的mempool效率较高？**

## 算法  

## Intel指令级优化  
* OpenMP指令（待续）  
* SIMD指令（待续）  
